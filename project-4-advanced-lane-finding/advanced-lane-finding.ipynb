{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Camera Calibration\n",
    "# first prepare object and image points by running the findChessboardCorners on all test images\n",
    "# then save \n",
    "\n",
    "# path to image dirs\n",
    "base_path = './training/'\n",
    "calibration_path = 'camera_cal/'\n",
    "output_path = 'cali_out/'\n",
    "saved_calibration_file = 'calibration_output.p'\n",
    "\n",
    "\n",
    "def read_image(image_path):\n",
    "    \"\"\"\n",
    "        read the image in the given path\n",
    "        as cv2.imread returns BGR images, apply transformation to expected RGB\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# simple helper to read an image and convert it to gray scale\n",
    "def read_and_convert_to_gray_scale(image_path):\n",
    "    image = read_image(image_path)\n",
    "    return convert_to_gray_scale(image)\n",
    "\n",
    "# convert BGR image to gray scale\n",
    "def convert_to_gray_scale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def persist_calibration_info(camera_matrix, distortion_coeffs):\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"camera_matrix\"] = camera_matrix\n",
    "    dist_pickle[\"distortion_coeffs\"] = distortion_coeffs\n",
    "    pickle.dump(dist_pickle, open(base_path + output_path + saved_calibration_file, \"wb\"))\n",
    "\n",
    "# use provided calibration images to find object and image points needed for camera calibration computations\n",
    "def calibrate_camera(nx=9, ny=6):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((ny * nx, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    obj_points = [] # 3d points in real world space\n",
    "    img_points = [] # 2d points in image plane.\n",
    "\n",
    "    image_regex = 'calibration*.jpg'\n",
    "    images = glob.glob(base_path + calibration_path + image_regex)\n",
    "\n",
    "    for idx, image in enumerate(images):\n",
    "        # get gray scale image\n",
    "        gray = read_and_convert_to_gray_scale(image)\n",
    "\n",
    "        # find chessboard corners\n",
    "        found, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if found == True:\n",
    "            obj_points.append(objp)\n",
    "            img_points.append(corners)\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(obj_points, img_points, gray.shape[::-1], None, None)\n",
    "    return mtx, dist\n",
    "\n",
    "\n",
    "img = read_image(base_path + calibration_path + 'calibration2.jpg')\n",
    "mtx, dist = calibrate_camera()\n",
    "dst = cv2.undistort(img, mtx, dist, None, None)\n",
    "cv2.imwrite(base_path + output_path + 'calibration2_undistorted.jpg', dst)\n",
    "\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dst)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transformation and thresholding functions.\n",
    "\n",
    "# define filter/transformtions\n",
    "# 1 absolute sobel threshold\n",
    "# 2 gradient magnitude threshold\n",
    "# 3 gradient direction threshold\n",
    "# 4 color space threshold(s)\n",
    "# 5 maybe try laplace\n",
    "\n",
    "def apply_threshold_to_image(image, threshold):\n",
    "    binary_output = np.zeros_like(image)\n",
    "    binary_output[(image >= threshold[0]) & (image <= threshold[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def scale_to_eight_bit(image):\n",
    "    return np.uint8(255 * image / np.max(image))\n",
    "\n",
    "def scale_and_apply_threshold(image, threshold):\n",
    "    scaled = scale_to_eight_bit(image)\n",
    "    return apply_threshold_to_image(scaled, threshold)\n",
    "\n",
    "def apply_x_and_y_sobel(image, sobel_kernel=3):\n",
    "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    return sobel_x, sobel_y\n",
    "\n",
    "# applies sobel operator on image and applies threshold\n",
    "# assumes image has been read by using cv2.imread, resulting in an BGR image.\n",
    "def absolute_sobel_threshold(image, orient='x', sobel_kernel=3, threshold=(0, 255)):\n",
    "    \"\"\"\n",
    "        transform image to binary image using the the sobel operator for a given direction and threshold\n",
    "    \"\"\"\n",
    "\n",
    "    gray = convert_to_gray_scale(image)\n",
    "    \n",
    "    # Calculate directional gradient\n",
    "    orientation = (1, 0) if orient == 'x' else (0, 1)\n",
    "    sobel = cv2.Sobel(gray, cv2.CV_64F, orientation[0], orientation[1], ksize=sobel_kernel)\n",
    "    \n",
    "    abs_sobel = np.absolute(sobel)\n",
    "\n",
    "    return scale_and_apply_threshold(abs_sobel, threshold)\n",
    "\n",
    "# finds the magnitude of the gradient and filters given the threshold\n",
    "# assumes image has been read by using cv2.imread, resulting in an BGR image.\n",
    "def magnitude_threshold(image, sobel_kernel=3, threshold=(0, 255)):\n",
    "    \"\"\"\n",
    "        transform image to binary image using the magnitude of the gradient and specified threshold\n",
    "    \"\"\"\n",
    "\n",
    "    gray = convert_to_gray_scale(image)\n",
    "    \n",
    "    # take the gradient in x and y separately\n",
    "    sobel_x, sobel_y = apply_x_and_y_sobel(gray, sobel_kernel=sobel_kernel)\n",
    "    \n",
    "    # calculate the magnitude \n",
    "    magnitude = np.sqrt(np.multiply(sobel_x, sobel_x) + np.multiply(sobel_y, sobel_y))\n",
    "    \n",
    "    return scale_and_apply_threshold(magnitude, threshold)\n",
    "\n",
    "# threshold on the direction of gradient\n",
    "# assumes image has been read by using cv2.imread, resulting in an BGR image.\n",
    "def gradient_direction_threshold(image, sobel_kernel=3, threshold=(0, np.pi/2)):\n",
    "    \"\"\"\n",
    "        transform image to binary image using the direction of the gradient and specified threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    gray = convert_to_gray_scale(image)\n",
    "    \n",
    "    # take the gradient in x and y separately\n",
    "    sobel_x, sobel_y = apply_x_and_y_sobel(gray, sobel_kernel=sobel_kernel)\n",
    "    \n",
    "    abs_sobel_x = np.absolute(sobel_x)\n",
    "    abs_sobel_y = np.absolute(sobel_y)\n",
    "    \n",
    "    # calculate the direction of the gradient \n",
    "    gradient_dir = np.arctan2(abs_sobel_y, abs_sobel_x)\n",
    "    \n",
    "    return apply_threshold_to_image(gradient_dir, threshold)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove distortion from images\n",
    "def undistort(image):\n",
    "    \"\"\"\n",
    "        undistort an image according to the coefficients computed above.\n",
    "    \"\"\"\n",
    "    global mtx, dist\n",
    "    undist = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute transformation matrixes\n",
    "def get_perspective_transform(image, src):\n",
    "    \"\"\"\n",
    "        compute M and Minv for image warping from the given src and dst points\n",
    "    \"\"\"\n",
    "    img_size = image.shape\n",
    "    dst = np.array([[0.23*img_size[1], 0.14*img_size[0]],\n",
    "                    [0.77*img_size[1], 0.14*img_size[0]],\n",
    "                    [0.77*img_size[1], img_size[0]],\n",
    "                    [0.23*img_size[1], img_size[0]]], np.float32)\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    return M, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform perspective transform\n",
    "def warp_image(undistorted_image, M):\n",
    "    \"\"\"\n",
    "        warp perspective of the image with the given matrix M\n",
    "    \"\"\"\n",
    "    img_size = (undistorted_image.shape[1], undistorted_image.shape[0])\n",
    "    warped = cv2.warpPerspective(undistorted_image, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import atan2, ceil, cos, sin\n",
    "\n",
    "# use hough transform to find possible base points for warping the image to bird's eye view\n",
    "def find_perspective_transform_src_points(image):\n",
    "    \"\"\"\n",
    "        using hough transform to find suitable src coordinates for image transformation\n",
    "    \"\"\"\n",
    "    # Computing perspective points automatically\n",
    "    rho = 2              # distance resolution in pixels of the Hough grid\n",
    "    theta = np.pi/180  # angular resolution in radians of the Hough grid\n",
    "    threshold = 100       # minimum number of votes (intersections in Hough grid cell)\n",
    "    min_line_length = 100 # minimum number of pixels making up a line\n",
    "    max_line_gap = 25    # maximum gap in pixels between connectable line segments\n",
    "\n",
    "    angle_min_mag = 25 * np.pi/180\n",
    "    angle_max_mag = 40 * np.pi/180\n",
    "\n",
    "    lane_markers_x = [[], []]\n",
    "    lane_markers_y = [[], []]\n",
    "    \n",
    "    masked_image = np.copy(image)\n",
    "    masked_image[:image.shape[0]*6//10,:] = 0\n",
    "    lines = cv2.HoughLinesP(masked_image, rho, theta, threshold, min_line_length, max_line_gap)\n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            theta = atan2(y1-y2, x2-x1)\n",
    "            rho = ((x1+x2) * cos(theta) + (y1+y2) * sin(theta))/2\n",
    "\n",
    "            if (abs(theta) >= angle_min_mag and abs(theta) <= angle_max_mag):\n",
    "                if theta > 0: # positive theta is downward in image space?\n",
    "                    i = 0 # Left lane marker\n",
    "                else:\n",
    "                    i = 1 # Right lane marker\n",
    "                lane_markers_x[i].append(x1)\n",
    "                lane_markers_x[i].append(x2)\n",
    "                lane_markers_y[i].append(y1)\n",
    "                lane_markers_y[i].append(y2)\n",
    "\n",
    "    if len(lane_markers_x[0]) < 1 or len(lane_markers_x[1]) < 1:\n",
    "        # Failed to find two lane markers, falling back to defaults based on image size.\n",
    "        img_size = image.shape\n",
    "        return np.array([[0.45*img_size[1], 0.63*img_size[0]],\n",
    "                         [0.55*img_size[1], 0.63*img_size[0]],\n",
    "                         [0.88*img_size[1], img_size[0]],\n",
    "                         [0.15*img_size[1], img_size[0]]], np.float32)\n",
    "    \n",
    "    \n",
    "    p_left  = np.polyfit(lane_markers_y[0], lane_markers_x[0], 1)\n",
    "    p_right = np.polyfit(lane_markers_y[1], lane_markers_x[1], 1)\n",
    "    \n",
    "    # Find intersection of the two lines\n",
    "    apex_pt = np.linalg.solve([[p_left[0], -1], [p_right[0], -1]], [-p_left[1], -p_right[1]])\n",
    "    top_y = ceil(apex_pt[0] + 0.075*image.shape[0])\n",
    "    \n",
    "    bl_pt = ceil(np.polyval(p_left, image.shape[0]))\n",
    "    tl_pt = ceil(np.polyval(p_left, top_y))\n",
    "    \n",
    "    br_pt = ceil(np.polyval(p_right, image.shape[0]))\n",
    "    tr_pt = ceil(np.polyval(p_right, top_y))\n",
    "\n",
    "    src_points = np.array([[tl_pt, top_y],\n",
    "                    [tr_pt, top_y],\n",
    "                    [br_pt, image.shape[0]],\n",
    "                    [bl_pt, image.shape[0]]], np.float32)\n",
    "\n",
    "    return src_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# apply thresholds to image\n",
    "# assumes that image has been undistorted and warped\n",
    "def apply_thresholds(image, draw_images=False):\n",
    "    \"\"\"\n",
    "        compute various binary images using different channels and thresholds\n",
    "        combine them into final image which will show the street lanes in white\n",
    "    \"\"\"\n",
    "    \n",
    "    s_channel = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)[:,:,2]\n",
    "    l_channel = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)[:,:,0]\n",
    "    b_channel = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)[:,:,2]\n",
    "    \n",
    "    s_binary = apply_threshold_to_image(s_channel, (150, 255)) # picks up yellow very well\n",
    "    l_binary = apply_threshold_to_image(l_channel, (225, 255)) # does not pick up yellow, but white\n",
    "    b_binary = apply_threshold_to_image(b_channel, (150, 200))\n",
    "    \n",
    "    combined_channel_binary = np.zeros_like(s_binary)\n",
    "    combined_channel_binary[(((l_binary == 1) & (s_binary == 1)) | (b_binary == 1))] = 1\n",
    "    \n",
    "    mag_binary = magnitude_threshold(image, sobel_kernel=3, threshold=(30, 100))\n",
    "    direction_binary = gradient_direction_threshold(image, sobel_kernel=15, threshold=(0.7, 1.3))\n",
    "    sobel_x = absolute_sobel_threshold(image, orient='x', sobel_kernel=9, threshold=(10, 100))\n",
    "    sobel_y = absolute_sobel_threshold(image, orient='y', sobel_kernel=9, threshold=(10, 100))\n",
    "    edges_binary = np.zeros_like(sobel_x)\n",
    "    edges_binary[(sobel_x == 1) & (sobel_y == 1) & (mag_binary == 1) & (direction_binary == 1)] = 1\n",
    "    \n",
    "    overall_binary = np.zeros_like(mag_binary)\n",
    "    overall_binary[(combined_channel_binary == 1) | (edges_binary == 1)] = 1\n",
    "    \n",
    "    \n",
    "    if draw_images:\n",
    "        f, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(20,10))\n",
    "        ax1.set_title('s channel')\n",
    "        ax1.imshow(s_binary, cmap='gray')\n",
    "\n",
    "        ax2.set_title('b channel')\n",
    "        ax2.imshow(b_binary, cmap='gray')\n",
    "\n",
    "        ax3.set_title('edges combined')\n",
    "        ax3.imshow(edges_binary, cmap='gray')\n",
    "\n",
    "        ax4.set_title('channels combined')\n",
    "        ax4.imshow(combined_channel_binary, cmap='gray')\n",
    "\n",
    "        ax5.set_title('combined')\n",
    "        ax5.imshow(overall_binary, cmap='gray')\n",
    "\n",
    "        ax6.set_title('original')\n",
    "        ax6.imshow(image)\n",
    "        \n",
    "    return overall_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks_cwt\n",
    "\n",
    "def find_lane_base_points(image, peak_threshold=25.0):\n",
    "    \"\"\"\n",
    "        use a histogram to find possible base points for lane lines\n",
    "    \"\"\"\n",
    "    hist = np.sum(image[int(image.shape[0]*0.5):,:], axis=0)\n",
    "    idx = find_peaks_cwt(hist, [100, 125, 150], max_distances=[100, 125, 150], noise_perc=50) \n",
    "\n",
    "    if len(idx) < 2: # should rarely ever happen if there's lanes in the picture\n",
    "        return None\n",
    "\n",
    "    # filter peaks to avoid noise.\n",
    "    width = image.shape[1]\n",
    "    idx = [i for i in idx if i > width * 0.075 # not on the far left\n",
    "           and i < width * 0.875 # neither on the far right\n",
    "           and max(hist[i-50:i+50]) > peak_threshold] # and has a minimum height\n",
    "    return [min(idx), max(idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_lanes(image, left_lane, right_lane, base_pts, num_bands=15, window_width=0.2):\n",
    "    \"\"\"\n",
    "        using a histogram and a sliding window, find lane pixels in the given iamge\n",
    "    \"\"\"\n",
    "\n",
    "    # setup variables\n",
    "    height, width = image.shape[0], image.shape[1]\n",
    "    band_height = int(1./num_bands * height)\n",
    "    band_width = int(window_width * width)\n",
    "\n",
    "    # arrays to track points for left and right\n",
    "    l_x, l_y, r_x, r_y = [], [], [], []\n",
    "\n",
    "    base_left, base_right = base_pts\n",
    "\n",
    "    # from bottom to top, go step wise through the image\n",
    "    for i in reversed(range(num_bands)):\n",
    "        w_left = image[i*band_height:(i+1)*band_height,base_left-band_width//2:base_left+band_width//2]\n",
    "        w_right = image[i*band_height:(i+1)*band_height,base_right-band_width//2:base_right+band_width//2]\n",
    "        \n",
    "        left_y_pt, left_x_pt = np.nonzero(w_left)\n",
    "        right_y_pt, right_x_pt = np.nonzero(w_right)\n",
    "        \n",
    "        l_x.extend(left_x_pt + base_left-band_width//2)\n",
    "        l_y.extend(left_y_pt + i*band_height)\n",
    "        r_x.extend(right_x_pt+ base_right-band_width//2)\n",
    "        r_y.extend(right_y_pt+ i*band_height)\n",
    "\n",
    "        # Find 'x' with maximum nonzero elements as baseline for next window\n",
    "        s_left = np.sum(w_left, axis=0)\n",
    "        s_right = np.sum(w_right, axis=0)\n",
    "        if np.any(s_left > 0):\n",
    "            base_left = np.argmax(s_left) + base_left-band_width//2\n",
    "        if np.any(s_right > 0):\n",
    "            base_right = np.argmax(s_right) + base_right-band_width//2\n",
    "    \n",
    "    # update lane with points found\n",
    "    left_lane.add_lane_pixels(l_x, l_y)\n",
    "    right_lane.add_lane_pixels(r_x, r_y)\n",
    "\n",
    "    return left_lane, right_lane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run for all test images\n",
    "for image_path in glob.glob('./training/test_images/test*.jpg'):\n",
    "    image = read_image(image_path)\n",
    "    undistorted = undistort(image)\n",
    "    combined_binary = apply_thresholds(image, draw_images=False)\n",
    "    src_points = find_perspective_transform_src_points(combined_binary)\n",
    "    M, _ = get_perspective_transform(combined_binary, src_points)\n",
    "    warped = warp_image(combined_binary, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define line class to keep track of lane in each frame (base idea taken from class material)\n",
    "import collections\n",
    "from itertools import chain, repeat\n",
    "    \n",
    "# conversion factors\n",
    "ym_per_pix = 30./720.\n",
    "xm_per_pix = 3.7/700.\n",
    "\n",
    "class Lane():\n",
    "    def __init__(self, base_pt, img_size, error_threshold=0.025):\n",
    "        \n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        \n",
    "        # x and y values of the last n fits of the line\n",
    "        self.recent_xfitted = collections.deque(maxlen=10)\n",
    "        self.recent_yfitted = collections.deque(maxlen=10)\n",
    "\n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]\n",
    "        \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "\n",
    "        self.current_xfit = None\n",
    "        \n",
    "        self.img_size = img_size\n",
    "        self.base_pt = base_pt\n",
    "        \n",
    "        self.yvals = np.linspace(0, img_size[0], 101) * 7.2 \n",
    "        self.mask = np.ones(img_size, dtype=np.uint8)*255\n",
    "        \n",
    "        self.dropped_frames = 0\n",
    "        self.error_threshold = error_threshold\n",
    "    \n",
    "    def add_lane_pixels(self, x, y):\n",
    "        # Use all pixels from previous detections for curve fit\n",
    "        x_hist = np.fromiter(chain(*self.recent_xfitted, x), np.int32)\n",
    "        y_hist = np.fromiter(chain(*self.recent_yfitted, y), np.int32)\n",
    "\n",
    "        try:\n",
    "            p_lane = np.polyfit(y_hist, x_hist, 2)\n",
    "            curvature = Lane.compute_curvature(x_hist, y_hist)\n",
    "            self.radius_of_curvature = curvature\n",
    "            self.detected = self.sanity_check_lane(curvature)\n",
    "        except:\n",
    "            self.detected = False\n",
    "\n",
    "        if self.detected:\n",
    "            x_fit = p_lane[0] * self.yvals**2 + p_lane[1] * self.yvals + p_lane[2]\n",
    "        \n",
    "            self.current_xfit = x_fit   # For drawing\n",
    "\n",
    "            self.recent_xfitted.append(x_fit)\n",
    "            self.recent_yfitted.append(self.yvals)\n",
    "            \n",
    "            self.dropped_frames = 0\n",
    "        else:\n",
    "            # use last fit as sanity check failed\n",
    "            x_fit = self.current_fit[0]*self.yvals**2 + self.current_fit[1]*self.yvals + self.current_fit[2]\n",
    "            self.dropped_frames += 1\n",
    "        \n",
    "        self.update_mask(x_fit)\n",
    "        \n",
    "    # compute curvate in real world space as defined in class material\n",
    "    @staticmethod\n",
    "    def compute_curvature(yvals, xvals):\n",
    "        fit_cr = np.polyfit(yvals * ym_per_pix, xvals * xm_per_pix, 2)\n",
    "        y_eval = np.max(yvals)\n",
    "        return ((1 + (2 * fit_cr[0] * y_eval + fit_cr[1])**2)**1.5) / np.absolute(2 * fit_cr[0])\n",
    "    \n",
    "    def sanity_check_lane(self, curvature):\n",
    "        # Return true if there is no prior data\n",
    "        if self.radius_of_curvature is None:\n",
    "            return True\n",
    "        \n",
    "        # check difference between given and previously computed curvature against the error threshold\n",
    "        k = 1. / curvature\n",
    "        k0 = 1. / self.radius_of_curvature\n",
    "        return abs(k - k0) / k0 <= self.error_threshold\n",
    "\n",
    "    def detect_from_mask(self, image):\n",
    "        mask_lanes = cv2.bitwise_and(image, self.mask)\n",
    "        all_pts = cv2.findNonZero(mask_lanes)\n",
    "        if all_pts is not None:\n",
    "            all_pts = all_pts.reshape((-1,2))\n",
    "            self.add_lane_pixels(all_pts[:,0], all_pts[:,1])\n",
    "        else:\n",
    "            self.detected = False\n",
    "    \n",
    "    def update_mask(self, x_fit):\n",
    "        self.mask.fill(0)\n",
    "        pts = np.transpose(np.vstack([x_fit, self.yvals])).reshape((-1,1,2)).astype(np.int32)\n",
    "        cv2.drawContours(self.mask, pts, -1, (255, 255, 255), thickness=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    global cam_mtx, cam_dist\n",
    "        \n",
    "    if process_image.cache is None:\n",
    "                \n",
    "        left_lane = Lane(int(0.16*image.shape[0]), image.shape[:2])\n",
    "        right_lane = Lane(int(0.62*image.shape[0]), image.shape[:2])\n",
    "\n",
    "        cache = {\n",
    "            'mtx': mtx,\n",
    "            'dist': dist,\n",
    "            'M': None,\n",
    "            'Minv': None,\n",
    "            'left': left_lane,\n",
    "            'right': right_lane,\n",
    "            'base_pts': None\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        cache = process_image.cache\n",
    "    \n",
    "\n",
    "    left_lane = cache['left']\n",
    "    right_lane = cache['right']\n",
    "\n",
    "    # preprocess image and find lanes using thresholding defined above\n",
    "    undistorted = undistort(image)\n",
    "    combined_binary = apply_thresholds(undistorted)\n",
    "    \n",
    "    if cache['M'] is None:\n",
    "        src = find_perspective_transform_src_points(combined_binary)\n",
    "        M, Minv = get_perspective_transform(image, src)\n",
    "        cache['M'] = M\n",
    "        cache['Minv'] = Minv\n",
    "    else:\n",
    "        M, Minv = cache['M'], cache['Minv']\n",
    "\n",
    "    warped = warp_image(combined_binary, M)\n",
    "    \n",
    "    base_pts = cache['base_pts']\n",
    "    if base_pts is None:\n",
    "        base_pts = find_lane_base_points(warped)\n",
    "\n",
    "    if ((left_lane is None or not left_lane.dropped_frames > 16) \n",
    "            or (right_lane is None or not right_lane.dropped_frames > 16)):\n",
    "        # detect from scratch\n",
    "        find_lanes(warped, left_lane, right_lane, base_pts)\n",
    "    else:\n",
    "        left_lane.detect_from_mask(warped)\n",
    "        right_lane.detect_from_mask(warped)\n",
    "\n",
    "    cache['base_pts'] = base_pts\n",
    "    process_image.cache = cache\n",
    "    \n",
    "    # create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(image).astype(np.uint8)\n",
    "    \n",
    "    yvals = left_lane.yvals\n",
    "    left_fitx = left_lane.current_xfit\n",
    "    right_fitx = right_lane.current_xfit\n",
    "    \n",
    "    # create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(image).astype(np.uint8)\n",
    "\n",
    "    # recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, yvals]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, yvals])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0, 255, 0))\n",
    "    \n",
    "    # warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    new_warp = warp_image(color_warp, Minv)\n",
    "    \n",
    "    # combine the result with the original image\n",
    "    result = cv2.addWeighted(undistorted, 1, new_warp, 0.3, 0)\n",
    "    \n",
    "    # print position off center and curvature information in image.\n",
    "    middle = (left_fitx[-1] + right_fitx[-1]) / 2.\n",
    "    veh_pos = image.shape[1] / 2. # assuming the camera is placed in the middle of the car.\n",
    "    \n",
    "    deviation = (veh_pos - middle) * xm_per_pix\n",
    "\n",
    "    label_left_curvature = 'left radius of curvature = {:.2f} m'.format(left_lane.radius_of_curvature)\n",
    "    label_right_curvature = 'right radius of curvature = {:.2f} m'.format(right_lane.radius_of_curvature)\n",
    "    label_off_center = 'vehicle is {:.2f}m {} off center'.format(abs(deviation), 'right' if deviation > 0 else 'left')\n",
    "    cv2.putText(result, label_left_curvature, (10, result.shape[0] - 600), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv2.putText(result, label_right_curvature, (10, result.shape[0] - 550), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "    cv2.putText(result, label_off_center, (10, result.shape[0] - 500), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "\n",
    "    cache['left'] = left_lane\n",
    "    cache['right'] = right_lane\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import video editing classes\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "def process_video(output_path, input_path):\n",
    "    process_image.cache = None # that's kind of a hack to initialize the cache of the process_image function\n",
    "    input_file = VideoFileClip(input_path)\n",
    "    standard_clip = input_file.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "    %time standard_clip.write_videofile(output_path, audio=False, threads=4)\n",
    "    return output_path\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standard video\n",
    "output = process_video('./training/project_4_standard.mp4', \"./training/project_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# challenge video\n",
    "output_challenge = process_video('./training/project_4_challenge.mp4', \"./training/challenge_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_challenge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hard challenge video\n",
    "output_hard = process_video('./training/project_4_harder_challenge.mp4', \"./training/harder_challenge_video.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
